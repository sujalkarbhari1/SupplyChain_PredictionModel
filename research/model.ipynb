{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8bb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing Logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename='classification_model.log',\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    force=True)\n",
    "\n",
    "# Import Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f21f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data ingestion\n",
    "def data_ingestion():\n",
    "  df = pd.read_csv(r'C:\\SupplyChain_PredictionModel\\data\\raw\\SupplyChain_Dataset.csv')\n",
    "  df.drop(columns=[\n",
    "        \"Customer_Email\",\n",
    "        \"Customer_Password\",\n",
    "        \"Customer_Fname\",\n",
    "        \"Customer_Lname\",\n",
    "        \"Product_Image\",\n",
    "        \"Product_Description\",\n",
    "        \"Order_Id\",\n",
    "        \"Customer_Id\",\n",
    "        'Customer_City',\n",
    "        'Customer_Country',\n",
    "        'Customer_Segment',\n",
    "        'Customer_State',\n",
    "        'Customer_Street',\n",
    "        'Customer_Zipcode',\n",
    "        'Order_City',\n",
    "        'Order_Country',\n",
    "        'Order_State',\n",
    "        'Order_Zipcode',\n",
    "        'Product_Status',\n",
    "        \"Order_Customer_Id\",\n",
    "        'Category_Id',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        'Order_Item_Id',\n",
    "        'Product_Category_Id',\n",
    "        'shipping_date_(DateOrders)',\n",
    "        'order_date_(DateOrders)',\n",
    "        'Product_Card_Id',\n",
    "        'Order_Item_Cardprod_Id',\n",
    "        'Department_Id',\n",
    "        \"Delivery_Status\",\n",
    "        \"Order_Status\",\n",
    "        \"Product_Name\",\n",
    "        'Order_Item_Discount_Rate'\n",
    "    ],axis=1, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71b8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_exploration(df):\n",
    "\n",
    "    # Segregate numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(exclude='object').columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    numerical_stats = []\n",
    "\n",
    "    # Numerical stats\n",
    "    for i in numerical_cols:\n",
    "\n",
    "        Q1 = df[i].quantile(0.25)\n",
    "        Q3 = df[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        LW = Q1 - 1.5 * IQR\n",
    "        UW = Q3 + 1.5 * IQR\n",
    "\n",
    "        outlier_flag = \"Has Outliers\" if ((df[i] < LW) | (df[i] > UW)).any() else \"No Outliers\"\n",
    "\n",
    "        num_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Maximum\": df[i].max(),\n",
    "            \"Minimum\": df[i].min(),\n",
    "            \"Mean\": df[i].mean(),\n",
    "            \"Median\": df[i].median(),\n",
    "            \"Q1\": Q1,\n",
    "            \"Q3\": Q3,\n",
    "            \"IQR\": IQR,\n",
    "            \"Skewness\": df[i].skew(),\n",
    "            \"Kurtosis\": df[i].kurtosis(),\n",
    "            \"Outlier Comment\": outlier_flag\n",
    "        })\n",
    "\n",
    "        numerical_stats.append(num_stats)\n",
    "\n",
    "    numerical_stats_report = pd.DataFrame(numerical_stats)\n",
    "\n",
    "    # Categorical stats\n",
    "    categorical_stats = []\n",
    "\n",
    "    for i in categorical_cols:\n",
    "\n",
    "        cat_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Unique_Values\": df[i].nunique(),\n",
    "            \"Mode\": df[i].mode()[0],\n",
    "            \"Value_Counts\": df[i].value_counts().to_dict()\n",
    "        })\n",
    "\n",
    "        categorical_stats.append(cat_stats)\n",
    "\n",
    "    categorical_stats_report = pd.DataFrame(categorical_stats)\n",
    "\n",
    "    return numerical_stats_report, categorical_stats_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "\n",
    "    # Split the data into X and y\n",
    "    X = df.drop(columns=['Late_delivery_risk'], axis=1)\n",
    "    y = df['Late_delivery_risk']\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "    # Encoding categorical columns\n",
    "    categorical_cols = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "    # Scaling numerical columns\n",
    "    numerical_cols = X_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        ms = MinMaxScaler()\n",
    "        X_train[col] = ms.fit_transform(X_train[[col]])\n",
    "        X_test[col] = ms.transform(X_test[[col]])\n",
    "\n",
    "    # Apply SMOTE only on training data\n",
    "    smote = SMOTE(random_state=1)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d19c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "def model_training(X_train, X_test, y_train, y_test):\n",
    "  models = {\n",
    "      \"Logistic Regression\": LogisticRegression(),\n",
    "      \"Decision Tree\": DecisionTreeClassifier(),\n",
    "      \"Random Forest\": RandomForestClassifier(),\n",
    "      \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "      \"AdaBoost\": AdaBoostClassifier(),\n",
    "      \"Bagging\": BaggingClassifier(),\n",
    "      \"XGBoost\": XGBClassifier(),\n",
    "  }\n",
    "  results = {}\n",
    "  for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "  return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f154633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Stats Report:\n",
      "                         Features     Maximum     Minimum        Mean  \\\n",
      "0        Days_for_shipping_(real)     6.00000     0.00000    3.497654   \n",
      "1   Days_for_shipment_(scheduled)     4.00000     0.00000    2.931847   \n",
      "2               Benefit_per_order   911.79999 -4274.97998   21.974989   \n",
      "3              Sales_per_customer  1939.98999     7.49000  183.107609   \n",
      "4              Late_delivery_risk     1.00000     0.00000    0.548291   \n",
      "5             Order_Item_Discount   500.00000     0.00000   20.664741   \n",
      "6        Order_Item_Product_Price  2000.00000    10.00000  141.245016   \n",
      "7         Order_Item_Profit_Ratio     0.50000    -2.75000    0.120647   \n",
      "8             Order_Item_Quantity     5.00000     1.00000    2.127638   \n",
      "9                           Sales  1999.98999     9.99000  203.772097   \n",
      "10               Order_Item_Total  1939.98999     7.49000  183.107609   \n",
      "11         Order_Profit_Per_Order   911.80000 -4274.98000   21.974989   \n",
      "12                  Product_Price  1999.99000     9.99000  141.232547   \n",
      "\n",
      "       Median      Q1         Q3        IQR  Skewness   Kurtosis  \\\n",
      "0     3.00000    2.00    5.00000    3.00000  0.084771  -1.007914   \n",
      "1     4.00000    2.00    4.00000    2.00000 -0.731998  -1.022949   \n",
      "2    31.52000    7.00   64.80000   57.80000 -4.741834  71.377258   \n",
      "3   163.99001  104.38  247.39999  143.01999  2.888446  23.920362   \n",
      "4     1.00000    0.00    1.00000    1.00000 -0.194074  -1.962357   \n",
      "5    14.00000    5.40   29.99000   24.59000  3.039796  25.231267   \n",
      "6    60.00000   50.00  200.00000  150.00000  3.190901  23.310724   \n",
      "7     0.27000    0.08    0.36000    0.28000 -2.893531  10.157225   \n",
      "8     1.00000    1.00    3.00000    2.00000  0.880252  -0.753702   \n",
      "9   199.92000  119.98  299.95001  179.97001  2.884249  23.936562   \n",
      "10  163.99001  104.38  247.39999  143.01999  2.888446  23.920362   \n",
      "11   31.52000    7.00   64.80000   57.80000 -4.741834  71.377259   \n",
      "12   59.99000   50.00  199.99000  149.99000  3.191020  23.313000   \n",
      "\n",
      "   Outlier Comment  \n",
      "0      No Outliers  \n",
      "1      No Outliers  \n",
      "2     Has Outliers  \n",
      "3     Has Outliers  \n",
      "4      No Outliers  \n",
      "5     Has Outliers  \n",
      "6     Has Outliers  \n",
      "7     Has Outliers  \n",
      "8      No Outliers  \n",
      "9     Has Outliers  \n",
      "10    Has Outliers  \n",
      "11    Has Outliers  \n",
      "12    Has Outliers  \n",
      "\n",
      "Categorical Stats Report:\n",
      "          Features  Unique_Values             Mode  \\\n",
      "0             Type              4            DEBIT   \n",
      "1    Category_Name             50           Cleats   \n",
      "2  Department_Name             11         Fan Shop   \n",
      "3           Market              5            LATAM   \n",
      "4     Order_Region             23  Central America   \n",
      "5    Shipping_Mode              4   Standard Class   \n",
      "\n",
      "                                        Value_Counts  \n",
      "0  {'DEBIT': 69295, 'TRANSFER': 49883, 'PAYMENT':...  \n",
      "1  {'Cleats': 24551, 'Men's Footwear': 22246, 'Wo...  \n",
      "2  {'Fan Shop': 66861, 'Apparel': 48998, 'Golf': ...  \n",
      "3  {'LATAM': 51594, 'Europe': 50252, 'Pacific Asi...  \n",
      "4  {'Central America': 28341, 'Western Europe': 2...  \n",
      "5  {'Standard Class': 107752, 'Second Class': 352...  \n",
      "Logistic Regression Accuracy: 0.9750904793559347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24532\n",
      "           1       0.96      1.00      0.98     29624\n",
      "\n",
      "    accuracy                           0.98     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.98      0.98      0.98     54156\n",
      "\n",
      "Decision Tree Accuracy: 0.9564960484526184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     24532\n",
      "           1       0.96      0.96      0.96     29624\n",
      "\n",
      "    accuracy                           0.96     54156\n",
      "   macro avg       0.96      0.96      0.96     54156\n",
      "weighted avg       0.96      0.96      0.96     54156\n",
      "\n",
      "Random Forest Accuracy: 0.9731516360144767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     24532\n",
      "           1       0.96      1.00      0.98     29624\n",
      "\n",
      "    accuracy                           0.97     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.97      0.97      0.97     54156\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9750904793559347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24532\n",
      "           1       0.96      1.00      0.98     29624\n",
      "\n",
      "    accuracy                           0.98     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.98      0.98      0.98     54156\n",
      "\n",
      "AdaBoost Accuracy: 0.9556281852426324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     24532\n",
      "           1       0.96      0.96      0.96     29624\n",
      "\n",
      "    accuracy                           0.96     54156\n",
      "   macro avg       0.96      0.96      0.96     54156\n",
      "weighted avg       0.96      0.96      0.96     54156\n",
      "\n",
      "Bagging Accuracy: 0.9670581283698944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     24532\n",
      "           1       0.96      0.98      0.97     29624\n",
      "\n",
      "    accuracy                           0.97     54156\n",
      "   macro avg       0.97      0.97      0.97     54156\n",
      "weighted avg       0.97      0.97      0.97     54156\n",
      "\n",
      "XGBoost Accuracy: 0.9743888027180737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24532\n",
      "           1       0.96      1.00      0.98     29624\n",
      "\n",
      "    accuracy                           0.97     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.98      0.97      0.97     54156\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24532\n",
      "           1       0.96      1.00      0.98     29624\n",
      "\n",
      "    accuracy                           0.97     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.98      0.97      0.97     54156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    logging.info(\"Data Ingestion Started\")\n",
    "    df = data_ingestion()\n",
    "    logging.info(\"Data Ingestion Completed\")\n",
    "    logging.info(\"Data Exploration Started\")\n",
    "    numerical_stats_report, categorical_stats_report = data_exploration(df)\n",
    "    logging.info(\"Data Exploration Completed\")\n",
    "    print(\"Numerical Stats Report:\")\n",
    "    print(numerical_stats_report)\n",
    "    print(\"\\nCategorical Stats Report:\")\n",
    "    print(categorical_stats_report)\n",
    "    logging.info(\"Data Preprocessing Started\")\n",
    "    X_train, X_test, y_train, y_test = data_preprocessing(df)\n",
    "    logging.info(\"Data Preprocessing Completed\")\n",
    "    logging.info(\"Model Training and Evaluation Started\")\n",
    "    model_report = model_training(X_train, X_test, y_train, y_test)\n",
    "    logging.info(\"Model Training and Evaluation Completed\")\n",
    "    print(model_report)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supplychain-predictionmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
