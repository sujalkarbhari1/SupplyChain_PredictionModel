{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6ba2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Import logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filemode=\"w\",\n",
    "                    filename=\"regression_model.log\",\n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "                    force=True)\n",
    "\n",
    "# Import Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score,root_mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler,LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51aa1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data ingestion\n",
    "def data_ingestion():\n",
    "  df = pd.read_csv(r'C:\\SupplyChain_PredictionModel\\data\\raw\\SupplyChain_Dataset.csv')\n",
    "  df.drop(columns=[\n",
    "        \"Customer_Email\",\n",
    "        \"Customer_Password\",\n",
    "        \"Customer_Fname\",\n",
    "        \"Customer_Lname\",\n",
    "        \"Product_Image\",\n",
    "        \"Product_Description\",\n",
    "        \"Order_Id\",\n",
    "        \"Customer_Id\",\n",
    "        'Customer_City',\n",
    "        'Customer_Country',\n",
    "        'Customer_Segment',\n",
    "        'Customer_State',\n",
    "        'Customer_Street',\n",
    "        'Customer_Zipcode',\n",
    "        'Order_City',\n",
    "        'Order_Country',\n",
    "        'Order_State',\n",
    "        'Order_Zipcode',\n",
    "        'Product_Status',\n",
    "        \"Order_Customer_Id\",\n",
    "        'Category_Id',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        'Order_Item_Id',\n",
    "        'Product_Category_Id',\n",
    "        'shipping_date_(DateOrders)',\n",
    "        'order_date_(DateOrders)',\n",
    "        'Product_Card_Id',\n",
    "        'Order_Item_Cardprod_Id',\n",
    "        'Department_Id',\n",
    "        \"Delivery_Status\",\n",
    "        \"Order_Status\",\n",
    "        \"Product_Name\",\n",
    "        'Order_Item_Discount_Rate'\n",
    "    ],axis=1, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64967d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_exploration(df):\n",
    "\n",
    "    # Segregate numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(exclude='object').columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    numerical_stats = []\n",
    "\n",
    "    # Numerical stats\n",
    "    for i in numerical_cols:\n",
    "\n",
    "        Q1 = df[i].quantile(0.25)\n",
    "        Q3 = df[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        LW = Q1 - 1.5 * IQR\n",
    "        UW = Q3 + 1.5 * IQR\n",
    "\n",
    "        outlier_flag = \"Has Outliers\" if ((df[i] < LW) | (df[i] > UW)).any() else \"No Outliers\"\n",
    "\n",
    "        num_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Maximum\": df[i].max(),\n",
    "            \"Minimum\": df[i].min(),\n",
    "            \"Mean\": df[i].mean(),\n",
    "            \"Median\": df[i].median(),\n",
    "            \"Q1\": Q1,\n",
    "            \"Q3\": Q3,\n",
    "            \"IQR\": IQR,\n",
    "            \"Skewness\": df[i].skew(),\n",
    "            \"Kurtosis\": df[i].kurtosis(),\n",
    "            \"Outlier Comment\": outlier_flag\n",
    "        })\n",
    "\n",
    "        numerical_stats.append(num_stats)\n",
    "\n",
    "    numerical_stats_report = pd.DataFrame(numerical_stats)\n",
    "\n",
    "    # Categorical stats\n",
    "    categorical_stats = []\n",
    "\n",
    "    for i in categorical_cols:\n",
    "\n",
    "        cat_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Unique_Values\": df[i].nunique(),\n",
    "            \"Mode\": df[i].mode()[0],\n",
    "            \"Value_Counts\": df[i].value_counts().to_dict()\n",
    "        })\n",
    "\n",
    "        categorical_stats.append(cat_stats)\n",
    "\n",
    "    categorical_stats_report = pd.DataFrame(categorical_stats)\n",
    "\n",
    "    return numerical_stats_report, categorical_stats_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce28022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df,target_col ='Sales'):\n",
    "\n",
    "    # Split the data into X and y\n",
    "    X = df.drop(columns=[target_col], axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "    # Encoding categorical columns\n",
    "    categorical_cols = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "    # Scaling numerical columns\n",
    "    numerical_cols = X_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        ms = MinMaxScaler()\n",
    "        X_train[col] = ms.fit_transform(X_train[[col]])\n",
    "        X_test[col] = ms.transform(X_test[[col]])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ce48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge Regression\": Ridge(),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "        \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "        \"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n",
    "        \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "        \"Bagging Regressor\": BaggingRegressor(),\n",
    "        \"XGBoost Regressor\": XGBRegressor()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        results[name] = {\"RMSE\": rmse, \"R2 Score\": r2}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ddad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kflod using\n",
    "def k_fold_cv(X_train, y_train, folds=10):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(),\n",
    "        \"Random Forest\": RandomForestRegressor(),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "        \"AdaBoost\": AdaBoostRegressor(),\n",
    "        \"Bagging\": BaggingRegressor(),\n",
    "        \"XGBoost\": XGBRegressor(),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(\n",
    "            model, X_train, y_train, cv=folds, scoring=\"r2\"\n",
    "        )\n",
    "        results.append([name, scores.mean(), scores.std()])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        results, columns=[\"Model Name\", \"CV Mean R2 Score\", \"CV STD\"]).sort_values(\"CV Mean R2 Score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X_train, y_train, folds=5):\n",
    "    tuning_config = {\n",
    "\n",
    "        \"Linear Regression\": {\n",
    "            \"model\": LinearRegression(),\n",
    "            \"params\": {\n",
    "                \"fit_intercept\": [True, False],\n",
    "                \"positive\": [True, False]\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"XGBoost\": {\n",
    "            \"model\": XGBRegressor(),\n",
    "            \"params\": {\n",
    "                \"eta\": [0.1, 0.2, 0.3],\n",
    "                \"max_depth\": [3, 5, 7],\n",
    "                \"gamma\": [0, 10, 20],\n",
    "                \"reg_lambda\": [0, 1],\n",
    "                \"n_estimators\": [100, 200]\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"Decision Tree\": {\n",
    "            \"model\": DecisionTreeRegressor(),\n",
    "            \"params\": {\n",
    "                \"max_depth\": [None, 5, 10, 15],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 2, 4]\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestRegressor(),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [100, 200],\n",
    "                \"max_depth\": [5, 10, 15],\n",
    "                \"max_features\": [\"sqrt\", \"log2\"]\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"Bagging Regressor\": {\n",
    "            \"model\": BaggingRegressor(),\n",
    "            \"params\": {\n",
    "                \"n_estimators\":  [10, 50, 100],\n",
    "                \"max_samples\": [0.5, 0.7, 1.0],\n",
    "                \"max_features\": [0.5, 0.7, 1.0]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "    for name, cfg in tuning_config.items():\n",
    "        grid = GridSearchCV(\n",
    "            cfg[\"model\"],\n",
    "            cfg[\"params\"],\n",
    "            cv=folds,\n",
    "            scoring=\"r2\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa15ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Stats Report:\n",
      "                         Features     Maximum     Minimum        Mean  \\\n",
      "0        Days_for_shipping_(real)     6.00000     0.00000    3.497654   \n",
      "1   Days_for_shipment_(scheduled)     4.00000     0.00000    2.931847   \n",
      "2               Benefit_per_order   911.79999 -4274.97998   21.974989   \n",
      "3              Sales_per_customer  1939.98999     7.49000  183.107609   \n",
      "4              Late_delivery_risk     1.00000     0.00000    0.548291   \n",
      "5             Order_Item_Discount   500.00000     0.00000   20.664741   \n",
      "6        Order_Item_Product_Price  2000.00000    10.00000  141.245016   \n",
      "7         Order_Item_Profit_Ratio     0.50000    -2.75000    0.120647   \n",
      "8             Order_Item_Quantity     5.00000     1.00000    2.127638   \n",
      "9                           Sales  1999.98999     9.99000  203.772097   \n",
      "10               Order_Item_Total  1939.98999     7.49000  183.107609   \n",
      "11         Order_Profit_Per_Order   911.80000 -4274.98000   21.974989   \n",
      "12                  Product_Price  1999.99000     9.99000  141.232547   \n",
      "\n",
      "       Median      Q1         Q3        IQR  Skewness   Kurtosis  \\\n",
      "0     3.00000    2.00    5.00000    3.00000  0.084771  -1.007914   \n",
      "1     4.00000    2.00    4.00000    2.00000 -0.731998  -1.022949   \n",
      "2    31.52000    7.00   64.80000   57.80000 -4.741834  71.377258   \n",
      "3   163.99001  104.38  247.39999  143.01999  2.888446  23.920362   \n",
      "4     1.00000    0.00    1.00000    1.00000 -0.194074  -1.962357   \n",
      "5    14.00000    5.40   29.99000   24.59000  3.039796  25.231267   \n",
      "6    60.00000   50.00  200.00000  150.00000  3.190901  23.310724   \n",
      "7     0.27000    0.08    0.36000    0.28000 -2.893531  10.157225   \n",
      "8     1.00000    1.00    3.00000    2.00000  0.880252  -0.753702   \n",
      "9   199.92000  119.98  299.95001  179.97001  2.884249  23.936562   \n",
      "10  163.99001  104.38  247.39999  143.01999  2.888446  23.920362   \n",
      "11   31.52000    7.00   64.80000   57.80000 -4.741834  71.377259   \n",
      "12   59.99000   50.00  199.99000  149.99000  3.191020  23.313000   \n",
      "\n",
      "   Outlier Comment  \n",
      "0      No Outliers  \n",
      "1      No Outliers  \n",
      "2     Has Outliers  \n",
      "3     Has Outliers  \n",
      "4      No Outliers  \n",
      "5     Has Outliers  \n",
      "6     Has Outliers  \n",
      "7     Has Outliers  \n",
      "8      No Outliers  \n",
      "9     Has Outliers  \n",
      "10    Has Outliers  \n",
      "11    Has Outliers  \n",
      "12    Has Outliers  \n",
      "\n",
      "Categorical Stats Report:\n",
      "          Features  Unique_Values             Mode  \\\n",
      "0             Type              4            DEBIT   \n",
      "1    Category_Name             50           Cleats   \n",
      "2  Department_Name             11         Fan Shop   \n",
      "3           Market              5            LATAM   \n",
      "4     Order_Region             23  Central America   \n",
      "5    Shipping_Mode              4   Standard Class   \n",
      "\n",
      "                                        Value_Counts  \n",
      "0  {'DEBIT': 69295, 'TRANSFER': 49883, 'PAYMENT':...  \n",
      "1  {'Cleats': 24551, 'Men's Footwear': 22246, 'Wo...  \n",
      "2  {'Fan Shop': 66861, 'Apparel': 48998, 'Golf': ...  \n",
      "3  {'LATAM': 51594, 'Europe': 50252, 'Pacific Asi...  \n",
      "4  {'Central America': 28341, 'Western Europe': 2...  \n",
      "5  {'Standard Class': 107752, 'Second Class': 352...  \n",
      "\n",
      "Model Results:\n",
      "{'Linear Regression': {'RMSE': 0.0015101610143671183, 'R2 Score': 0.9999999998659757}, 'Ridge Regression': {'RMSE': 0.4688017737079539, 'R2 Score': 0.9999870843643307}, 'Lasso Regression': {'RMSE': 23.373303898840135, 'R2 Score': 0.9678946428897106}, 'Decision Tree Regressor': {'RMSE': 0.5298921090400394, 'R2 Score': 0.9999834989265359}, 'Random Forest Regressor': {'RMSE': 0.4131038224747024, 'R2 Score': 0.9999899710441257}, 'Gradient Boosting Regressor': {'RMSE': 3.0253137000126333, 'R2 Score': 0.9994621290097055}, 'AdaBoost Regressor': {'RMSE': 18.332912391872423, 'R2 Score': 0.9802484937953022}, 'Bagging Regressor': {'RMSE': 0.4824988908720522, 'R2 Score': 0.999986318619164}, 'XGBoost Regressor': {'RMSE': 0.5145795033770473, 'R2 Score': 0.9999844388295294}}\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "          Model Name  CV Mean R2 Score        CV STD\n",
      "0  Linear Regression          1.000000  6.104016e-12\n",
      "6            XGBoost          0.999983  3.683113e-06\n",
      "2      Random Forest          0.999975  3.184137e-05\n",
      "5            Bagging          0.999975  2.902203e-05\n",
      "1      Decision Tree          0.999545  1.307960e-03\n",
      "3  Gradient Boosting          0.999458  5.472159e-05\n",
      "4           AdaBoost          0.980603  1.333992e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(best_models)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(cv_results)\n\u001b[32m     26\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mStarting hyperparameter tuning...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m best_models = \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mHyperparameter tuning completed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest Models from Hyperparameter Tuning:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mhyperparameter_tuning\u001b[39m\u001b[34m(X_train, y_train, folds)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, cfg \u001b[38;5;129;01min\u001b[39;00m tuning_config.items():\n\u001b[32m     53\u001b[39m     grid = GridSearchCV(\n\u001b[32m     54\u001b[39m         cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     55\u001b[39m         cfg[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m         n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     59\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m best_models[name] = grid.best_estimator_\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_models\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1612\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SupplyChain_PredictionModel\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    logging.info(\"Starting data ingestion...\")\n",
    "    df = data_ingestion()\n",
    "    logging.info(\"Data ingestion completed.\")\n",
    "    logging.info(\"Starting data exploration...\")\n",
    "    numerical_stats_report, categorical_stats_report = data_exploration(df)\n",
    "    logging.info(\"Data exploration completed.\")\n",
    "    print(\"Numerical Stats Report:\")\n",
    "    print(numerical_stats_report)\n",
    "    print(\"\\nCategorical Stats Report:\")\n",
    "    print(categorical_stats_report)\n",
    "    logging.info(\"Starting data preprocessing...\")\n",
    "    X_train, X_test, y_train, y_test = data_preprocessing(df)\n",
    "    logging.info(\"Data preprocessing completed.\")\n",
    "    logging.info(\"Starting model training...\")\n",
    "    results = model_training(\n",
    "        X_train, X_test, y_train, y_test\n",
    "    )\n",
    "    print(\"\\nModel Results:\")\n",
    "    print(results)\n",
    "    logging.info(\"Starting k-fold cross-validation...\")\n",
    "    cv_results = k_fold_cv(X_train, y_train)\n",
    "    logging.info(\"K-fold cross-validation completed.\")\n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(cv_results)\n",
    "    logging.info(\"Starting hyperparameter tuning...\")\n",
    "    best_models = hyperparameter_tuning(X_train, y_train,folds=5)\n",
    "    logging.info(\"Hyperparameter tuning completed.\")\n",
    "    print(\"\\nBest Models from Hyperparameter Tuning:\")\n",
    "    print(best_models)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supplychain-predictionmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
