{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8951a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing Logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename='classification_model.log',\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    force=True)\n",
    "\n",
    "\n",
    "# Importing Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from flaml import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8960887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data ingestion\n",
    "def data_ingestion():\n",
    "  df = pd.read_csv(r'C:\\SupplyChain_PredictionModel\\data\\raw\\SupplyChain_Dataset.csv')\n",
    "  df.drop(columns=[\n",
    "        \"Customer_Email\",\n",
    "        \"Customer_Password\",\n",
    "        \"Customer_Fname\",\n",
    "        \"Customer_Lname\",\n",
    "        \"Product_Image\",\n",
    "        \"Product_Description\",\n",
    "        \"Order_Id\",\n",
    "        \"Customer_Id\",\n",
    "        'Customer_City',\n",
    "        'Customer_Country',\n",
    "        'Customer_Segment',\n",
    "        'Customer_State',\n",
    "        'Customer_Street',\n",
    "        'Customer_Zipcode',\n",
    "        'Order_City',\n",
    "        'Order_Country',\n",
    "        'Order_State',\n",
    "        'Order_Zipcode',\n",
    "        'Product_Status',\n",
    "        \"Order_Customer_Id\",\n",
    "        'Category_Id',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        'Order_Item_Id',\n",
    "        'Product_Category_Id',\n",
    "        'shipping_date_(DateOrders)',\n",
    "        'order_date_(DateOrders)',\n",
    "        'Product_Card_Id',\n",
    "        'Order_Item_Cardprod_Id',\n",
    "        'Department_Id',\n",
    "        \"Delivery_Status\",\n",
    "        \"Order_Status\",\n",
    "        \"Product_Name\",\n",
    "        'Order_Item_Discount_Rate'\n",
    "    ],axis=1, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b531c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def data_exploration(df):\n",
    "    \n",
    "    # Segregate numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(exclude='object').columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    numerical_stats = []\n",
    "    # Numerical stats\n",
    "    for i in numerical_cols:\n",
    "        Q1 = df[i].quantile(0.25)\n",
    "        Q3 = df[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        LW = Q1 - 1.5 * IQR\n",
    "        UW = Q3 + 1.5 * IQR\n",
    "        outlier_flag = \"Has Outliers\" if ((df[i] < LW) | (df[i] > UW)).any() else \"No Outliers\"\n",
    "        \n",
    "        num_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Maximum\": df[i].max(),\n",
    "            \"Minimum\": df[i].min(),\n",
    "            \"Mean\": df[i].mean(),\n",
    "            \"Median\": df[i].median(),\n",
    "            \"Q1\": Q1,\n",
    "            \"Q3\": Q3,\n",
    "            \"IQR\": IQR,\n",
    "            \"Skewness\": df[i].skew(),\n",
    "            \"Kurtosis\": df[i].kurtosis(),\n",
    "            \"Outlier Comment\": outlier_flag\n",
    "        })\n",
    "\n",
    "        numerical_stats.append(num_stats)\n",
    "\n",
    "    numerical_stats_report = pd.DataFrame(numerical_stats)\n",
    "\n",
    "    # Categorical stats\n",
    "    categorical_stats = []\n",
    "\n",
    "    for i in categorical_cols:\n",
    "\n",
    "        cat_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Unique_Values\": df[i].nunique(),\n",
    "            \"Mode\": df[i].mode()[0],\n",
    "            \"Value_Counts\": df[i].value_counts().to_dict()\n",
    "        })\n",
    "\n",
    "        categorical_stats.append(cat_stats)\n",
    "\n",
    "    categorical_stats_report = pd.DataFrame(categorical_stats)\n",
    "\n",
    "    return numerical_stats_report, categorical_stats_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df356041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df,target_col = 'Late_delivery_risk'):\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    print(\"Split data completed.\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e40d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    print(\"Split train and test data completed.\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1ed200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor(X):\n",
    "    num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    numeric_pipeline = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, num_cols),\n",
    "        (\"cat\", categorical_pipeline, cat_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"Preprocessor Created\")\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d61257ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(preprocessor, X_train, X_test):\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    print(\"Preprocessing Applied\")\n",
    "    return X_train_processed, X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e50dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(\"SMOTE Applied\")\n",
    "    print(\"Class Distribution After SMOTE:\", np.bincount(y_resampled))\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "806f1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flaml(X_train, y_train):\n",
    "    automl = AutoML()\n",
    "\n",
    "    settings = {\n",
    "        \"time_budget\": 60,\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"task\": \"classification\",\n",
    "        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgboost\", \"lrl2\"],\n",
    "        \"log_file_name\": \"flaml.log\",\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    print(\"FLAML Training Completed\")\n",
    "    print(\"Best Model:\", automl.model.estimator)\n",
    "\n",
    "    return automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665017d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a53892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical Stats:\n",
      "                         Features     Maximum     Minimum        Mean  \\\n",
      "0        Days_for_shipping_(real)     6.00000     0.00000    3.497654   \n",
      "1   Days_for_shipment_(scheduled)     4.00000     0.00000    2.931847   \n",
      "2               Benefit_per_order   911.79999 -4274.97998   21.974989   \n",
      "3              Sales_per_customer  1939.98999     7.49000  183.107609   \n",
      "4              Late_delivery_risk     1.00000     0.00000    0.548291   \n",
      "5             Order_Item_Discount   500.00000     0.00000   20.664741   \n",
      "6        Order_Item_Product_Price  2000.00000    10.00000  141.245016   \n",
      "7         Order_Item_Profit_Ratio     0.50000    -2.75000    0.120647   \n",
      "8             Order_Item_Quantity     5.00000     1.00000    2.127638   \n",
      "9                           Sales  1999.98999     9.99000  203.772097   \n",
      "10               Order_Item_Total  1939.98999     7.49000  183.107609   \n",
      "11         Order_Profit_Per_Order   911.80000 -4274.98000   21.974989   \n",
      "12                  Product_Price  1999.99000     9.99000  141.232547   \n",
      "\n",
      "       Median      Q1         Q3        IQR  Skewness   Kurtosis  \\\n",
      "0     3.00000    2.00    5.00000    3.00000  0.084771  -1.007914   \n",
      "1     4.00000    2.00    4.00000    2.00000 -0.731998  -1.022949   \n",
      "2    31.52000    7.00   64.80000   57.80000 -4.741834  71.377258   \n",
      "3   163.99001  104.38  247.39999  143.01999  2.888446  23.920362   \n",
      "4     1.00000    0.00    1.00000    1.00000 -0.194074  -1.962357   \n",
      "5    14.00000    5.40   29.99000   24.59000  3.039796  25.231267   \n",
      "6    60.00000   50.00  200.00000  150.00000  3.190901  23.310724   \n",
      "7     0.27000    0.08    0.36000    0.28000 -2.893531  10.157225   \n",
      "8     1.00000    1.00    3.00000    2.00000  0.880252  -0.753702   \n",
      "9   199.92000  119.98  299.95001  179.97001  2.884249  23.936562   \n",
      "10  163.99001  104.38  247.39999  143.01999  2.888446  23.920362   \n",
      "11   31.52000    7.00   64.80000   57.80000 -4.741834  71.377259   \n",
      "12   59.99000   50.00  199.99000  149.99000  3.191020  23.313000   \n",
      "\n",
      "   Outlier Comment  \n",
      "0      No Outliers  \n",
      "1      No Outliers  \n",
      "2     Has Outliers  \n",
      "3     Has Outliers  \n",
      "4      No Outliers  \n",
      "5     Has Outliers  \n",
      "6     Has Outliers  \n",
      "7     Has Outliers  \n",
      "8      No Outliers  \n",
      "9     Has Outliers  \n",
      "10    Has Outliers  \n",
      "11    Has Outliers  \n",
      "12    Has Outliers  \n",
      "\n",
      "Categorical Stats:\n",
      "          Features  Unique_Values             Mode  \\\n",
      "0             Type              4            DEBIT   \n",
      "1    Category_Name             50           Cleats   \n",
      "2  Department_Name             11         Fan Shop   \n",
      "3           Market              5            LATAM   \n",
      "4     Order_Region             23  Central America   \n",
      "5    Shipping_Mode              4   Standard Class   \n",
      "\n",
      "                                        Value_Counts  \n",
      "0  {'DEBIT': 69295, 'TRANSFER': 49883, 'PAYMENT':...  \n",
      "1  {'Cleats': 24551, 'Men's Footwear': 22246, 'Wo...  \n",
      "2  {'Fan Shop': 66861, 'Apparel': 48998, 'Golf': ...  \n",
      "3  {'LATAM': 51594, 'Europe': 50252, 'Pacific Asi...  \n",
      "4  {'Central America': 28341, 'Western Europe': 2...  \n",
      "5  {'Standard Class': 107752, 'Second Class': 352...  \n",
      "Split data completed.\n",
      "Split train and test data completed.\n",
      "Preprocessor Created\n",
      "Preprocessing Applied\n",
      "SMOTE Applied\n",
      "Class Distribution After SMOTE: [69232 69232]\n",
      "[flaml.automl.logger: 02-24 20:07:15] {2375} INFO - task = classification\n",
      "[flaml.automl.logger: 02-24 20:07:15] {2386} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 02-24 20:07:15] {2489} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 02-24 20:07:15] {2606} INFO - List of ML learners in AutoML Run: ['rf', 'extra_tree', 'xgboost', 'lrl2']\n",
      "[flaml.automl.logger: 02-24 20:07:15] {2911} INFO - iteration 0, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3046} INFO - Estimated sufficient time budget=21866s. Estimated necessary time budget=33s.\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3097} INFO -  at 0.4s,\testimator rf's best error=1.1447e-01,\tbest estimator rf's best error=1.1447e-01\n",
      "[flaml.automl.logger: 02-24 20:07:16] {2911} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3097} INFO -  at 0.6s,\testimator xgboost's best error=6.3696e-02,\tbest estimator xgboost's best error=6.3696e-02\n",
      "[flaml.automl.logger: 02-24 20:07:16] {2911} INFO - iteration 2, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3097} INFO -  at 0.9s,\testimator rf's best error=5.2213e-02,\tbest estimator rf's best error=5.2213e-02\n",
      "[flaml.automl.logger: 02-24 20:07:16] {2911} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3097} INFO -  at 1.0s,\testimator xgboost's best error=6.3696e-02,\tbest estimator rf's best error=5.2213e-02\n",
      "[flaml.automl.logger: 02-24 20:07:16] {2911} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3097} INFO -  at 1.1s,\testimator rf's best error=5.2213e-02,\tbest estimator rf's best error=5.2213e-02\n",
      "[flaml.automl.logger: 02-24 20:07:16] {2911} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:16] {3097} INFO -  at 1.3s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-24 20:07:16] {2911} INFO - iteration 6, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:17] {3097} INFO -  at 1.4s,\testimator extra_tree's best error=2.0264e-01,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-24 20:07:17] {2911} INFO - iteration 7, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:17] {3097} INFO -  at 1.6s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-24 20:07:17] {2911} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:17] {3097} INFO -  at 1.9s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-24 20:07:17] {2911} INFO - iteration 9, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:17] {3097} INFO -  at 2.1s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-24 20:07:17] {2911} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:17] {3097} INFO -  at 2.2s,\testimator extra_tree's best error=1.9362e-01,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-24 20:07:17] {2911} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:17] {3097} INFO -  at 2.3s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:17] {2911} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:18] {3097} INFO -  at 2.4s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:18] {2911} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:18] {3097} INFO -  at 2.6s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:18] {2911} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:18] {3097} INFO -  at 2.7s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:18] {2911} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:18] {3097} INFO -  at 2.9s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:18] {2911} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:18] {3097} INFO -  at 3.2s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:18] {2911} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:19] {3097} INFO -  at 3.6s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:19] {2911} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:19] {3097} INFO -  at 4.2s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:19] {2911} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:20] {3097} INFO -  at 5.3s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-24 20:07:20] {2911} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:21] {3097} INFO -  at 6.1s,\testimator xgboost's best error=2.2604e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:21] {2911} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:23] {3097} INFO -  at 7.5s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:23] {2911} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:23] {3097} INFO -  at 8.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:23] {2911} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:24] {3097} INFO -  at 8.8s,\testimator xgboost's best error=2.2604e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:24] {2911} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:25] {3097} INFO -  at 9.8s,\testimator xgboost's best error=2.2604e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:25] {2911} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:25] {3097} INFO -  at 10.0s,\testimator extra_tree's best error=1.9362e-01,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:25] {2911} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:26] {3097} INFO -  at 11.2s,\testimator xgboost's best error=2.2604e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:26] {2911} INFO - iteration 27, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:27] {3097} INFO -  at 11.6s,\testimator lrl2's best error=2.7804e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:27] {2911} INFO - iteration 28, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:27] {3097} INFO -  at 11.8s,\testimator lrl2's best error=2.7732e-02,\tbest estimator xgboost's best error=2.2604e-02\n",
      "[flaml.automl.logger: 02-24 20:07:27] {2911} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:28] {3097} INFO -  at 12.5s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:28] {2911} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:29] {3097} INFO -  at 14.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:29] {2911} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:30] {3097} INFO -  at 14.9s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:30] {2911} INFO - iteration 32, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:31] {3097} INFO -  at 15.9s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:31] {2911} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:32] {3097} INFO -  at 16.7s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:32] {2911} INFO - iteration 34, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:33] {3097} INFO -  at 17.7s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:33] {2911} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:34] {3097} INFO -  at 18.4s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:34] {2911} INFO - iteration 36, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:34] {3097} INFO -  at 18.7s,\testimator lrl2's best error=2.7732e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:34] {2911} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:35] {3097} INFO -  at 19.7s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:35] {2911} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:35] {3097} INFO -  at 20.3s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:35] {2911} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:36] {3097} INFO -  at 20.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:36] {2911} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:37] {3097} INFO -  at 21.7s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:37] {2911} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:38] {3097} INFO -  at 22.9s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:38] {2911} INFO - iteration 42, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:39] {3097} INFO -  at 23.9s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:39] {2911} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:40] {3097} INFO -  at 24.6s,\testimator xgboost's best error=2.2532e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:40] {2911} INFO - iteration 44, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:40] {3097} INFO -  at 24.9s,\testimator lrl2's best error=2.7298e-02,\tbest estimator xgboost's best error=2.2532e-02\n",
      "[flaml.automl.logger: 02-24 20:07:40] {2911} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:41] {3097} INFO -  at 25.7s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:41] {2911} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:41] {3097} INFO -  at 25.9s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:41] {2911} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:42] {3097} INFO -  at 26.6s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:42] {2911} INFO - iteration 48, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:43] {3097} INFO -  at 27.7s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:43] {2911} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:43] {3097} INFO -  at 28.0s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:43] {2911} INFO - iteration 50, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:43] {3097} INFO -  at 28.2s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:43] {2911} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:44] {3097} INFO -  at 29.1s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:44] {2911} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:45] {3097} INFO -  at 30.2s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:45] {2911} INFO - iteration 53, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:46] {3097} INFO -  at 30.4s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:46] {2911} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:46] {3097} INFO -  at 31.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:46] {2911} INFO - iteration 55, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:47] {3097} INFO -  at 31.4s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:47] {2911} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:47] {3097} INFO -  at 31.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:47] {2911} INFO - iteration 57, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:47] {3097} INFO -  at 31.8s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:47] {2911} INFO - iteration 58, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:07:49] {3097} INFO -  at 34.0s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:49] {2911} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:50] {3097} INFO -  at 35.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:50] {2911} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:51] {3097} INFO -  at 36.0s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:51] {2911} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:52] {3097} INFO -  at 36.5s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:52] {2911} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:52] {3097} INFO -  at 37.2s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:52] {2911} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:53] {3097} INFO -  at 38.0s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:53] {2911} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:55] {3097} INFO -  at 39.8s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:55] {2911} INFO - iteration 65, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:07:56] {3097} INFO -  at 40.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:56] {2911} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:57] {3097} INFO -  at 42.2s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:57] {2911} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:07:58] {3097} INFO -  at 42.9s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:58] {2911} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:07:59] {3097} INFO -  at 44.3s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:07:59] {2911} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:00] {3097} INFO -  at 45.0s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:08:00] {2911} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:02] {3097} INFO -  at 46.4s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:08:02] {2911} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:02] {3097} INFO -  at 47.2s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:08:02] {2911} INFO - iteration 72, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:08:05] {3097} INFO -  at 49.4s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-24 20:08:05] {2911} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:05] {3097} INFO -  at 50.2s,\testimator xgboost's best error=2.2171e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:05] {2911} INFO - iteration 74, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:08:08] {3097} INFO -  at 52.4s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:08] {2911} INFO - iteration 75, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:08:08] {3097} INFO -  at 53.3s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:08] {2911} INFO - iteration 76, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:08:09] {3097} INFO -  at 54.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:09] {2911} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:10] {3097} INFO -  at 55.0s,\testimator xgboost's best error=2.2171e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:10] {2911} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:08:11] {3097} INFO -  at 55.9s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:11] {2911} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 02-24 20:08:12] {3097} INFO -  at 57.0s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:12] {2911} INFO - iteration 80, current learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:08:12] {3125} INFO - stop trying learner lrl2\n",
      "[flaml.automl.logger: 02-24 20:08:12] {2911} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:08:13] {3097} INFO -  at 57.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:13] {2911} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:14] {3097} INFO -  at 58.6s,\testimator xgboost's best error=2.2171e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:14] {2911} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 02-24 20:08:15] {3097} INFO -  at 59.4s,\testimator xgboost's best error=2.2171e-02,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:15] {2911} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl.logger: 02-24 20:08:15] {3097} INFO -  at 60.1s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2171e-02\n",
      "[flaml.automl.logger: 02-24 20:08:16] {3359} INFO - retrain xgboost for 0.8s\n",
      "[flaml.automl.logger: 02-24 20:08:16] {3362} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=np.float64(0.8877871568076),\n",
      "              colsample_bynode=None,\n",
      "              colsample_bytree=np.float64(0.8309395100662509), device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, feature_weights=None,\n",
      "              gamma=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None,\n",
      "              learning_rate=np.float64(0.02486146664480422), max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=19,\n",
      "              min_child_weight=np.float64(1.481745188432456), missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=4,\n",
      "              n_jobs=-1, num_parallel_tree=None, ...)\n",
      "[flaml.automl.logger: 02-24 20:08:16] {2636} INFO - fit succeeded\n",
      "[flaml.automl.logger: 02-24 20:08:16] {2637} INFO - Time taken to find the best model: 50.18871092796326\n",
      "FLAML Training Completed\n",
      "Best Model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=np.float64(0.8877871568076),\n",
      "              colsample_bynode=None,\n",
      "              colsample_bytree=np.float64(0.8309395100662509), device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, feature_weights=None,\n",
      "              gamma=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None,\n",
      "              learning_rate=np.float64(0.02486146664480422), max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=19,\n",
      "              min_child_weight=np.float64(1.481745188432456), missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=4,\n",
      "              n_jobs=-1, num_parallel_tree=None, ...)\n",
      "\n",
      "Accuracy: 0.9752566659280597\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24411\n",
      "           1       0.96      1.00      0.98     29745\n",
      "\n",
      "    accuracy                           0.98     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.98      0.98      0.98     54156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def main():\n",
    "    \n",
    "    logging.info('Data Loading Started')\n",
    "    df = data_ingestion()\n",
    "    logging.info('Data Loaded Successfully')\n",
    "\n",
    "    logging.info('Data Exploration Started')\n",
    "    numerical_stats_report, categorical_stats_report = data_exploration(df)\n",
    "    print('\\nNumerical Stats:')\n",
    "    print(numerical_stats_report)\n",
    "    print('\\nCategorical Stats:')\n",
    "    print(categorical_stats_report)\n",
    "    logging.info('Data Exploration Completed')\n",
    "    \n",
    "    logging.info('Split the data Started')\n",
    "    X, y = split_data(df)\n",
    "    logging.info('Split the data Completed')\n",
    "\n",
    "    logging.info('Train Test Split Started')\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "    logging.info('Train Test Split Completed')\n",
    "\n",
    "    logging.info('Creating a Preprocessor')\n",
    "    preprocessor = create_preprocessor(X_train)\n",
    "    logging.info('Preprocessor created successfully')\n",
    "    \n",
    "    logging.info('Applying Preprocessing')\n",
    "    X_train_processed, X_test_processed = apply_preprocessing(preprocessor, X_train, X_test)\n",
    "    logging.info('Preprocessing Completed')\n",
    "    \n",
    "    logging.info('Applying Smote')\n",
    "    X_resampled, y_resampled = apply_smote(X_train_processed, y_train)\n",
    "    logging.info('Smote Applied Successfully')\n",
    "    \n",
    "    logging.info('Training Model')\n",
    "    model = train_flaml(X_resampled, y_resampled)\n",
    "    logging.info('Training Completed')\n",
    "    \n",
    "    logging.info('Model Evaluation Started')\n",
    "    evaluate_model(model, X_test_processed, y_test)\n",
    "    logging.info('Model Evaluation Completed')\n",
    "\n",
    "    with open(\"best_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    with open(\"preprocessor.pkl\", \"wb\") as f:\n",
    "        pickle.dump(preprocessor, f)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e59bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180519 entries, 0 to 180518\n",
      "Data columns (total 19 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   Type                           180519 non-null  object \n",
      " 1   Days_for_shipping_(real)       180519 non-null  int64  \n",
      " 2   Days_for_shipment_(scheduled)  180519 non-null  int64  \n",
      " 3   Benefit_per_order              180519 non-null  float64\n",
      " 4   Sales_per_customer             180519 non-null  float64\n",
      " 5   Late_delivery_risk             180519 non-null  int64  \n",
      " 6   Category_Name                  180519 non-null  object \n",
      " 7   Department_Name                180519 non-null  object \n",
      " 8   Market                         180519 non-null  object \n",
      " 9   Order_Item_Discount            180519 non-null  float64\n",
      " 10  Order_Item_Product_Price       180519 non-null  int64  \n",
      " 11  Order_Item_Profit_Ratio        180519 non-null  float64\n",
      " 12  Order_Item_Quantity            180519 non-null  int64  \n",
      " 13  Sales                          180519 non-null  float64\n",
      " 14  Order_Item_Total               180519 non-null  float64\n",
      " 15  Order_Profit_Per_Order         180519 non-null  float64\n",
      " 16  Order_Region                   180519 non-null  object \n",
      " 17  Product_Price                  180519 non-null  float64\n",
      " 18  Shipping_Mode                  180519 non-null  object \n",
      "dtypes: float64(8), int64(5), object(6)\n",
      "memory usage: 26.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data_ingestion()\n",
    "df.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supplychain-predictionmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
