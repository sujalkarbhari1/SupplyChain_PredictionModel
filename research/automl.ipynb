{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8951a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing Logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename='classification_model.log',\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    force=True)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from flaml import AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8960887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data ingestion\n",
    "def data_ingestion():\n",
    "  df = pd.read_csv(r'C:\\SupplyChain_PredictionModel\\data\\raw\\SupplyChain_Dataset.csv')\n",
    "  df.drop(columns=[\n",
    "        \"Customer_Email\",\n",
    "        \"Customer_Password\",\n",
    "        \"Customer_Fname\",\n",
    "        \"Customer_Lname\",\n",
    "        \"Product_Image\",\n",
    "        \"Product_Description\",\n",
    "        \"Order_Id\",\n",
    "        \"Customer_Id\",\n",
    "        'Customer_City',\n",
    "        'Customer_Country',\n",
    "        'Customer_Segment',\n",
    "        'Customer_State',\n",
    "        'Customer_Street',\n",
    "        'Customer_Zipcode',\n",
    "        'Order_City',\n",
    "        'Order_Country',\n",
    "        'Order_State',\n",
    "        'Order_Zipcode',\n",
    "        'Product_Status',\n",
    "        \"Order_Customer_Id\",\n",
    "        'Category_Id',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        'Order_Item_Id',\n",
    "        'Product_Category_Id',\n",
    "        'shipping_date_(DateOrders)',\n",
    "        'order_date_(DateOrders)',\n",
    "        'Product_Card_Id',\n",
    "        'Order_Item_Cardprod_Id',\n",
    "        'Department_Id',\n",
    "        \"Delivery_Status\",\n",
    "        \"Order_Status\",\n",
    "        \"Product_Name\",\n",
    "        'Order_Item_Discount_Rate'\n",
    "    ],axis=1, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b531c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_exploration(df):\n",
    "    # Segregate numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(exclude='object').columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    numerical_stats = []\n",
    "\n",
    "    # Numerical stats\n",
    "    for i in numerical_cols:\n",
    "\n",
    "        Q1 = df[i].quantile(0.25)\n",
    "        Q3 = df[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        LW = Q1 - 1.5 * IQR\n",
    "        UW = Q3 + 1.5 * IQR\n",
    "\n",
    "        outlier_flag = \"Has Outliers\" if ((df[i] < LW) | (df[i] > UW)).any() else \"No Outliers\"\n",
    "\n",
    "        num_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Maximum\": df[i].max(),\n",
    "            \"Minimum\": df[i].min(),\n",
    "            \"Mean\": df[i].mean(),\n",
    "            \"Median\": df[i].median(),\n",
    "            \"Q1\": Q1,\n",
    "            \"Q3\": Q3,\n",
    "            \"IQR\": IQR,\n",
    "            \"Skewness\": df[i].skew(),\n",
    "            \"Kurtosis\": df[i].kurtosis(),\n",
    "            \"Outlier Comment\": outlier_flag\n",
    "        })\n",
    "\n",
    "        numerical_stats.append(num_stats)\n",
    "\n",
    "    numerical_stats_report = pd.DataFrame(numerical_stats)\n",
    "\n",
    "    # Categorical stats\n",
    "    categorical_stats = []\n",
    "\n",
    "    for i in categorical_cols:\n",
    "\n",
    "        cat_stats = OrderedDict({\n",
    "            \"Features\": i,\n",
    "            \"Unique_Values\": df[i].nunique(),\n",
    "            \"Mode\": df[i].mode()[0],\n",
    "            \"Value_Counts\": df[i].value_counts().to_dict()\n",
    "        })\n",
    "\n",
    "        categorical_stats.append(cat_stats)\n",
    "\n",
    "    categorical_stats_report = pd.DataFrame(categorical_stats)\n",
    "\n",
    "    return numerical_stats_report, categorical_stats_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df356041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df,target_col = 'Late_delivery_risk'):\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    print(\"Split data completed.\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e40d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    print(\"Split train and test data completed.\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1ed200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor(X):\n",
    "    num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    numeric_pipeline = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, num_cols),\n",
    "        (\"cat\", categorical_pipeline, cat_cols)\n",
    "    ])\n",
    "\n",
    "    print(\"Preprocessor Created\")\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61257ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(preprocessor, X_train, X_test):\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    print(\"Preprocessing Applied\")\n",
    "    return X_train_processed, X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e50dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(\"SMOTE Applied\")\n",
    "    print(\"Class Distribution After SMOTE:\", np.bincount(y_resampled))\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806f1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flaml(X_train, y_train):\n",
    "    automl = AutoML()\n",
    "\n",
    "    settings = {\n",
    "        \"time_budget\": 60,\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"task\": \"classification\",\n",
    "        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgboost\", \"lrl2\"],\n",
    "        \"log_file_name\": \"flaml.log\",\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    print(\"FLAML Training Completed\")\n",
    "    print(\"Best Model:\", automl.model.estimator)\n",
    "\n",
    "    return automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665017d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a53892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data completed.\n",
      "Split train and test data completed.\n",
      "Preprocessor Created\n",
      "Preprocessing Applied\n",
      "SMOTE Applied\n",
      "Class Distribution After SMOTE: [69232 69232]\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2375} INFO - task = classification\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2386} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2489} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2606} INFO - List of ML learners in AutoML Run: ['rf', 'extra_tree', 'xgboost', 'lrl2']\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2911} INFO - iteration 0, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:02] {3046} INFO - Estimated sufficient time budget=20149s. Estimated necessary time budget=31s.\n",
      "[flaml.automl.logger: 02-21 11:43:02] {3097} INFO -  at 0.4s,\testimator rf's best error=1.1447e-01,\tbest estimator rf's best error=1.1447e-01\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2911} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:02] {3097} INFO -  at 0.5s,\testimator xgboost's best error=6.3696e-02,\tbest estimator xgboost's best error=6.3696e-02\n",
      "[flaml.automl.logger: 02-21 11:43:02] {2911} INFO - iteration 2, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 0.6s,\testimator rf's best error=5.2213e-02,\tbest estimator rf's best error=5.2213e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 0.6s,\testimator xgboost's best error=6.3696e-02,\tbest estimator rf's best error=5.2213e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 0.7s,\testimator rf's best error=5.2213e-02,\tbest estimator rf's best error=5.2213e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 0.9s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 6, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 1.0s,\testimator extra_tree's best error=2.0264e-01,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 7, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 1.1s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 1.3s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 9, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:03] {3097} INFO -  at 1.4s,\testimator rf's best error=2.8093e-02,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-21 11:43:03] {2911} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.5s,\testimator extra_tree's best error=1.9362e-01,\tbest estimator rf's best error=2.8093e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.6s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.6s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.7s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.7s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.8s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 1.9s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 2.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 2.2s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:04] {3097} INFO -  at 2.4s,\testimator xgboost's best error=2.3254e-02,\tbest estimator xgboost's best error=2.3254e-02\n",
      "[flaml.automl.logger: 02-21 11:43:04] {2911} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:05] {3097} INFO -  at 2.6s,\testimator xgboost's best error=2.2460e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:05] {2911} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:05] {3097} INFO -  at 3.2s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:05] {2911} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:06] {3097} INFO -  at 3.7s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:06] {2911} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:06] {3097} INFO -  at 4.0s,\testimator xgboost's best error=2.2460e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:06] {2911} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:06] {3097} INFO -  at 4.3s,\testimator xgboost's best error=2.2460e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:06] {2911} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:06] {3097} INFO -  at 4.3s,\testimator extra_tree's best error=1.9362e-01,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:06] {2911} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:07] {3097} INFO -  at 4.7s,\testimator xgboost's best error=2.2460e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:07] {2911} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:07] {3097} INFO -  at 5.0s,\testimator xgboost's best error=2.2460e-02,\tbest estimator xgboost's best error=2.2460e-02\n",
      "[flaml.automl.logger: 02-21 11:43:07] {2911} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:07] {3097} INFO -  at 5.3s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:07] {2911} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:08] {3097} INFO -  at 5.6s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:08] {2911} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:08] {3097} INFO -  at 6.4s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:08] {2911} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:09] {3097} INFO -  at 6.9s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:09] {2911} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:09] {3097} INFO -  at 7.2s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:09] {2911} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:10] {3097} INFO -  at 7.7s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:10] {2911} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:11] {3097} INFO -  at 9.0s,\testimator xgboost's best error=2.2388e-02,\tbest estimator xgboost's best error=2.2388e-02\n",
      "[flaml.automl.logger: 02-21 11:43:11] {2911} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:12] {3097} INFO -  at 10.1s,\testimator xgboost's best error=2.2315e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:12] {2911} INFO - iteration 36, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:12] {3097} INFO -  at 10.3s,\testimator lrl2's best error=2.7804e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:12] {2911} INFO - iteration 37, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:12] {3097} INFO -  at 10.4s,\testimator lrl2's best error=2.7732e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:12] {2911} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:13] {3097} INFO -  at 10.8s,\testimator xgboost's best error=2.2315e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:13] {2911} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:13] {3097} INFO -  at 11.2s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:13] {2911} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:15] {3097} INFO -  at 12.6s,\testimator xgboost's best error=2.2315e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:15] {2911} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:15] {3097} INFO -  at 13.4s,\testimator xgboost's best error=2.2315e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:15] {2911} INFO - iteration 42, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:16] {3097} INFO -  at 13.8s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:16] {2911} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:16] {3097} INFO -  at 14.4s,\testimator xgboost's best error=2.2315e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:16] {2911} INFO - iteration 44, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:16] {3097} INFO -  at 14.5s,\testimator lrl2's best error=2.7732e-02,\tbest estimator xgboost's best error=2.2315e-02\n",
      "[flaml.automl.logger: 02-21 11:43:16] {2911} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:19] {3097} INFO -  at 17.2s,\testimator xgboost's best error=2.2099e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:19] {2911} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:20] {3097} INFO -  at 17.8s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:20] {2911} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:24] {3097} INFO -  at 21.9s,\testimator xgboost's best error=2.2099e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:24] {2911} INFO - iteration 48, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:24] {3097} INFO -  at 22.2s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:24] {2911} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:24] {3097} INFO -  at 22.3s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:24] {2911} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:26] {3097} INFO -  at 24.5s,\testimator xgboost's best error=2.2099e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:26] {2911} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:27] {3097} INFO -  at 24.6s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:27] {2911} INFO - iteration 52, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:27] {3097} INFO -  at 24.7s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:27] {2911} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:27] {3097} INFO -  at 25.2s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:27] {2911} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:27] {3097} INFO -  at 25.4s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:27] {2911} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:27] {3097} INFO -  at 25.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:27] {2911} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:28] {3097} INFO -  at 26.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:28] {2911} INFO - iteration 57, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:28] {3097} INFO -  at 26.1s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:28] {2911} INFO - iteration 58, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:28] {3097} INFO -  at 26.2s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:28] {2911} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:29] {3097} INFO -  at 26.7s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:29] {2911} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:29] {3097} INFO -  at 27.0s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:29] {2911} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:29] {3097} INFO -  at 27.5s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:29] {2911} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:30] {3097} INFO -  at 28.0s,\testimator xgboost's best error=2.2099e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:30] {2911} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:46] {3097} INFO -  at 44.2s,\testimator xgboost's best error=2.2099e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:46] {2911} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:47] {3097} INFO -  at 44.6s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:47] {2911} INFO - iteration 65, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:47] {3097} INFO -  at 45.0s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:47] {2911} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:47] {3097} INFO -  at 45.3s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:47] {2911} INFO - iteration 67, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:48] {3097} INFO -  at 45.7s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:48] {2911} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:48] {3097} INFO -  at 46.1s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:48] {2911} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:49] {3097} INFO -  at 46.7s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:49] {2911} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:49] {3097} INFO -  at 47.1s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:49] {2911} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:49] {3097} INFO -  at 47.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:49] {2911} INFO - iteration 72, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:50] {3097} INFO -  at 47.6s,\testimator lrl2's best error=2.7298e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:50] {2911} INFO - iteration 73, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:50] {3097} INFO -  at 47.7s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:50] {2911} INFO - iteration 74, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:50] {3097} INFO -  at 47.9s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:50] {2911} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:50] {3097} INFO -  at 48.2s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:50] {2911} INFO - iteration 76, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:51] {3097} INFO -  at 48.6s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:51] {2911} INFO - iteration 77, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:52] {3097} INFO -  at 49.7s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:52] {2911} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:52] {3097} INFO -  at 50.2s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:52] {2911} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:53] {3097} INFO -  at 50.8s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:53] {2911} INFO - iteration 80, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:54] {3097} INFO -  at 51.9s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:54] {2911} INFO - iteration 81, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:54] {3097} INFO -  at 52.5s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:54] {2911} INFO - iteration 82, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:56] {3097} INFO -  at 53.7s,\testimator lrl2's best error=2.5998e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:56] {2911} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 02-21 11:43:58] {3097} INFO -  at 55.9s,\testimator xgboost's best error=2.2099e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:58] {2911} INFO - iteration 84, current learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:58] {3125} INFO - stop trying learner lrl2\n",
      "[flaml.automl.logger: 02-21 11:43:58] {2911} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:58] {3097} INFO -  at 56.1s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:58] {2911} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:43:58] {3097} INFO -  at 56.5s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:58] {2911} INFO - iteration 87, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:59] {3097} INFO -  at 57.0s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:59] {2911} INFO - iteration 88, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:43:59] {3097} INFO -  at 57.5s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:43:59] {2911} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:44:00] {3097} INFO -  at 57.7s,\testimator extra_tree's best error=1.5780e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:44:00] {2911} INFO - iteration 90, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:44:00] {3097} INFO -  at 58.2s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:44:00] {2911} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl.logger: 02-21 11:44:01] {3097} INFO -  at 58.8s,\testimator extra_tree's best error=1.3584e-01,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:44:01] {2911} INFO - iteration 92, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:44:01] {3097} INFO -  at 59.2s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:44:01] {2911} INFO - iteration 93, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:44:01] {3097} INFO -  at 59.5s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:44:01] {2911} INFO - iteration 94, current learner rf\n",
      "[flaml.automl.logger: 02-21 11:44:02] {3097} INFO -  at 60.0s,\testimator rf's best error=2.8093e-02,\tbest estimator xgboost's best error=2.2099e-02\n",
      "[flaml.automl.logger: 02-21 11:44:04] {3359} INFO - retrain xgboost for 2.6s\n",
      "[flaml.automl.logger: 02-21 11:44:05] {3362} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=np.float64(0.9647949395335206),\n",
      "              colsample_bynode=None,\n",
      "              colsample_bytree=np.float64(0.9877878456495247), device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, feature_weights=None,\n",
      "              gamma=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None,\n",
      "              learning_rate=np.float64(0.05073658655640165), max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=np.float64(0.4739830538735349), missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=638,\n",
      "              n_jobs=-1, num_parallel_tree=None, ...)\n",
      "[flaml.automl.logger: 02-21 11:44:05] {2636} INFO - fit succeeded\n",
      "[flaml.automl.logger: 02-21 11:44:05] {2637} INFO - Time taken to find the best model: 17.188371419906616\n",
      "FLAML Training Completed\n",
      "Best Model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=np.float64(0.9647949395335206),\n",
      "              colsample_bynode=None,\n",
      "              colsample_bytree=np.float64(0.9877878456495247), device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, feature_weights=None,\n",
      "              gamma=None, grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None,\n",
      "              learning_rate=np.float64(0.05073658655640165), max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=np.float64(0.4739830538735349), missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=638,\n",
      "              n_jobs=-1, num_parallel_tree=None, ...)\n",
      "\n",
      "Accuracy: 0.9752566659280597\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24411\n",
      "           1       0.96      1.00      0.98     29745\n",
      "\n",
      "    accuracy                           0.98     54156\n",
      "   macro avg       0.98      0.97      0.97     54156\n",
      "weighted avg       0.98      0.98      0.98     54156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def main():\n",
    "\n",
    "    df = data_ingestion()\n",
    "    \n",
    "    X, y = split_data(df)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "    \n",
    "    preprocessor = create_preprocessor(X_train)\n",
    "    \n",
    "    X_train_processed, X_test_processed = apply_preprocessing(preprocessor, X_train, X_test)\n",
    "    \n",
    "    X_resampled, y_resampled = apply_smote(X_train_processed, y_train)\n",
    "    \n",
    "    model = train_flaml(X_resampled, y_resampled)\n",
    "    \n",
    "    evaluate_model(model, X_test_processed, y_test)\n",
    "\n",
    "    with open(\"best_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    with open(\"preprocessor.pkl\", \"wb\") as f:\n",
    "        pickle.dump(preprocessor, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supplychain-predictionmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
